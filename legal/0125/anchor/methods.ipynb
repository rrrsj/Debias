{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from random import randint\n",
    "from tqdm import trange\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output(message):\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-0125\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": message}\n",
    "    ],\n",
    "    temperature=0\n",
    "    )\n",
    "    response_message=json.loads(response.model_dump_json())\n",
    "    return response_message['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(ans,fact):\n",
    "    bias=''\n",
    "    if ans=='A':\n",
    "        bias='Among all the questions, 30% of them have the answer is A and 70% have the answer is B.'\n",
    "    else:\n",
    "        bias='Among all the questions, 70% of them have the answer is A and 30% have the answer is B.'\n",
    "    template='''Does the clause contain a license granted by one party to its counterparty?\n",
    "%s\n",
    "\n",
    "Clause: %s'''%(bias,fact)\n",
    "    return template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_bias(bias):\n",
    "    template='''The following is a prompt may contain cognitive biases. Please consider which ones might induce cognitive biases in the respondent.\n",
    "\n",
    "Example:[ Your previous output was A. This sentence contains an anchoring bias because it has presupposed option A.\n",
    "This Agreement shall be governed by, and construed in accordance with the law of the State of New York. This is a normal clause, so it does not contain cognitive bias.]\n",
    "\n",
    "Prompt: [%s]\n",
    "\n",
    "Output Format:\n",
    "\n",
    "Bias sentence1:\n",
    "...'''%(bias)\n",
    "    return template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite_bias(bias,judge):\n",
    "    template='''The following is a clause judgment task may contain cognitive biases. Delete all bias sentences in task according to the \"Bias Judgement\" such that a reviewer is not biased, maintain the normal task.\n",
    "\n",
    "Bias Judgment: [ %s ]\n",
    "\n",
    "Task: [ %s ]'''%(judge,bias)\n",
    "    return template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def judge_bias(input):\n",
    "    ans=get_output('''Please first break prompt all in [] into sentence by sentence, and then determine whether may contain cognitive biases that affect normal selection, and provide the reasons for the cognitive biases.\n",
    "\n",
    "Example:[ Your previous output was A. This sentence contains an anchoring bias because it has presupposed option A.\n",
    "This Agreement shall be governed by, and construed in accordance with the law of the State of New York. This is a normal clause, so it does not contain cognitive bias. ]         \n",
    "\n",
    "Prompt:[ %s ]'''%(input))\n",
    "    #print(ans)\n",
    "    if \"not contain\" in ans or \"Not contain\" in ans:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def judge_com(input):\n",
    "    ans=get_output('''Please help me determine whether the following question is complete or not.\n",
    "\n",
    "Prompt:[%s]'''%(input))\n",
    "    #print(ans)\n",
    "    if \"Incomplete\" in ans or \"incomplete\" in ans or 'not' in ans:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [52:36<00:00,  6.31s/it]  \n"
     ]
    }
   ],
   "source": [
    "data= open('../data/test.jsonl','r')\n",
    "for i in trange(500):\n",
    "    question=json.loads(data.readline())\n",
    "    all_num=0\n",
    "    linshi=get_prompt(str(question['ans']),question['question'])\n",
    "\n",
    "    while all_num<=2:\n",
    "        prompt=linshi\n",
    "        try_num=0\n",
    "        while judge_bias(prompt) and try_num<=2:\n",
    "            try:\n",
    "                judge=get_output(recognize_bias(prompt))\n",
    "                temp=get_output(rewrite_bias(prompt,judge))\n",
    "                prompt=re.findall(r\"Task:([\\S|\\s]*)\",temp, re.S|re.I)[0]\n",
    "                try_num=try_num+1 \n",
    "            except:\n",
    "                continue\n",
    "        all_num=all_num+1\n",
    "        if judge_com(prompt):\n",
    "            break\n",
    "        \n",
    "    prompt=prompt.replace('[','').replace(']','').replace('*','').strip()\n",
    "    ans=get_output(prompt+'\\nA.yes    B.no\\n\\nOutput format:\\nOption:A or B')\n",
    "    with open(\"anchor_0125_method1.jsonl\",\"a\",encoding='utf-8') as k:\n",
    "        input_dict={'number':i,'ans':str(question['ans']),'output':ans,'prompt':prompt}\n",
    "        input_json=json.dumps(input_dict)\n",
    "        k.write(input_json+'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
